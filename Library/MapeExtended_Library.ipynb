{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T01:28:49.420381Z",
     "start_time": "2021-06-27T01:28:49.371358Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVR_mapext:\n",
    "    \n",
    "    \"\"\"\n",
    "    SVR based on MAPE loss, and Elastic Net regularization. \n",
    "    Fits models where the values of the target variable are positive.\n",
    "    \n",
    "        -- Parameter --\n",
    "            C: determines the number of points that contribute to creation of the boundary. \n",
    "               (Default = 0.1)\n",
    "               The bigger the value of C, the lesser the points that the model will consider.\n",
    "               \n",
    "            epsilon: defines the maximum margin in the feature space (Default = 0.1).\n",
    "                        The bigger its value, the more general~underfitted the model is.\n",
    "                        \n",
    "            lamda: controls the implication of the weighted Elastic Net regularization.\n",
    "                        \n",
    "            kernel: name of the kernel that the model will use. Written in a string format.\n",
    "                    (Default = \"linear\"). \n",
    "        \n",
    "                    acceptable parameters: \n",
    "                        \"linear\", \"poly\", \"polynomial\", \"rbf\", \n",
    "                        \"laplacian\", \"cosine\".\n",
    "        \n",
    "                    for more information about individual kernels, visit the \n",
    "                    sklearn pairwise metrics affinities and kernels user guide.\n",
    "                    \n",
    "                    https://scikit-learn.org/stable/modules/metrics.html\n",
    "            \n",
    "            Specific kernel parameters: \n",
    "\n",
    "        --Methods--\n",
    "            fit(X, y): Learn from the data. Returns self.\n",
    "\n",
    "            predict(X_test): Predicts new points. Returns X_test labels.\n",
    "\n",
    "            coef_(): Returns alpha support vectors (sv) coefficient, X sv, and b.\n",
    "\n",
    "            For more information about each method, visit specific documentations.\n",
    "            \n",
    "        --Example-- \n",
    "            ## Call the class in a jupyter notebook\n",
    "            >>> %run MapeExtended_Library.ipynb\n",
    "            ...\n",
    "            ## Initialize the SVR object with custom parameters\n",
    "            >>> model = SVR_mapext(C = 10, kernel = \"rbf\", gamma = 0.1)\n",
    "            ...\n",
    "            ## Use the model to fit the data\n",
    "            >>> fitted_model = model.fit(X, y)\n",
    "            ...\n",
    "            ## Predict with the given model\n",
    "            >>> y_prediction = fitted_model.predict(X_test)\n",
    "            ...\n",
    "            ## e.g\n",
    "            >>> print(y_prediction)\n",
    "            np.array([12.8, 31.6, 16.2, 90.5, 28, 1, 49.7])\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C = 0.1, epsilon = 0.1, lamda = 0.2, kernel = \"linear\", **kernel_param):\n",
    "        import numpy as np\n",
    "        import cvxpy as cp\n",
    "        from sklearn.metrics.pairwise import pairwise_kernels\n",
    "        from sklearn.utils import check_X_y, check_array \n",
    "        self.cp = cp\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        self.kernel = kernel\n",
    "        self.pairwise_kernels = pairwise_kernels\n",
    "        self.kernel_param = kernel_param\n",
    "        self.check_X_y = check_X_y\n",
    "        self.check_array = check_array\n",
    "        self.lamda = lamda\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\" \n",
    "        Computes coefficients for new data prediction.\n",
    "        \n",
    "            --Parameters--\n",
    "                X: nxm matrix that contains all data points\n",
    "                   components. n is the number of points and\n",
    "                   m is the number of features of each point.\n",
    "                   \n",
    "                y: nx1 matrix that contains labels for all\n",
    "                   the points.\n",
    "            \n",
    "            --Returns--\n",
    "                self, containing all the parameters needed to \n",
    "                compute new data points.\n",
    "        \"\"\"\n",
    "        X, y = self.check_X_y(X, y)\n",
    "        # hyperparameters\n",
    "        C = self.C \n",
    "        epsilon =  self.epsilon\n",
    "        lamda = self.lamda\n",
    "        \n",
    "        kernel = self.kernel\n",
    "        pairwise_kernels = self.pairwise_kernels\n",
    "        cp = self.cp\n",
    "        # Useful parameters\n",
    "        ydim = y.shape[0]\n",
    "        onev = np.ones((ydim,1))\n",
    "        \n",
    "        # Matrices and constraints for the optimizer\n",
    "        K = pairwise_kernels(X, X, metric = kernel, **self.kernel_param)\n",
    "        A = onev.T\n",
    "        b = 0.0\n",
    "        G = np.concatenate((np.identity(ydim), -np.identity(ydim)))\n",
    "        h_ = np.concatenate((100*C*np.ones(ydim)/y, 100*C*np.ones(ydim)/y)); \n",
    "        h = h_.reshape(-1, 1)\n",
    "        \n",
    "        beta = cp.Variable((ydim, 1))\n",
    "        Ev = (epsilon*y.T)/100\n",
    "        \n",
    "        # loss function and constraints\n",
    "        min_fun = (1/2)*cp.quad_form(beta, K) - y.T @ beta + lamda*((1-Ev) @ cp.abs(beta) + Ev/2 @ beta**2)\n",
    "        objective = cp.Minimize(min_fun)\n",
    "        constraints = [A @ beta == b, G @ beta <= h]\n",
    "\n",
    "        \n",
    "        # Solver and solution\n",
    "        prob = cp.Problem(objective,constraints)\n",
    "        result = prob.solve()\n",
    "        \n",
    "        # Support vectors\n",
    "        beta_1 = np.array(beta.value).reshape(-1)\n",
    "        indx = abs(beta_1) > 5e-3\n",
    "        beta_sv = beta_1[indx]\n",
    "        x_sv = X[indx,:]\n",
    "        y_sv = y[indx]\n",
    "        \n",
    "        # get w_phi and b\n",
    "        k_sv = pairwise_kernels(x_sv, x_sv, metric = kernel, **self.kernel_param)\n",
    "        cons = np.where(beta_sv >= 0, 1 - epsilon/100, 1 + epsilon/100)\n",
    "        \n",
    "        w_phi = beta_sv @ k_sv\n",
    "        b = np.mean((y_sv*cons - w_phi)); self.b = b\n",
    "        self.beta_sv = beta_sv; self.x_sv = x_sv\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_):\n",
    "        \"\"\"Predicts new labels for a given set of new \n",
    "           independent variables (X_test).\n",
    "           \n",
    "           --Parameters--\n",
    "               X_test: nxm matrix containing all the points that \n",
    "                       will be predicted by the model.\n",
    "                       n is the number of points. m represents the\n",
    "                       number of features/dimensions of each point.\n",
    "            \n",
    "           --Returns--\n",
    "               a nx1 vector containing the predicted labels for the \n",
    "               input variables.\n",
    "                \n",
    "        \"\"\"\n",
    "        X_ = self.check_array(X_)\n",
    "        k_test = self.pairwise_kernels(self.x_sv, X_, metric = self.kernel, **self.kernel_param)\n",
    "        w_phi_test = self.beta_sv @ k_test\n",
    "        predict = w_phi_test + self.b\n",
    "        return predict\n",
    "    \n",
    "    def coef_(self):\n",
    "        \"\"\"--Returns--\n",
    "                - dual support vectors\n",
    "                - primal support vectors\n",
    "                - intercept\"\"\"\n",
    "        return self.beta_sv, self.x_sv, self.b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
